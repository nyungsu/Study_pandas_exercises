{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "The data have been modified to contain some missing values, identified by NaN.  \n",
    "Using pandas should make this exercise\n",
    "easier, in particular for the bonus question.\n",
    "\n",
    "You should be able to perform all of these operations without using\n",
    "a for loop or other looping construct.\n",
    "\n",
    "\n",
    "1. The data in 'wind.data' has the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\\n61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\\n61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\\n61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Yr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\n",
    "61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
    "61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\n",
    "61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The first three columns are year, month and day.  The\n",
    "   remaining 12 columns are average windspeeds in knots at 12\n",
    "   locations in Ireland on that day.   \n",
    "\n",
    "   More information about the dataset go [here](wind.desc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Assign it to a variable called data and replace the first 3 columns by a proper datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6574, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data'\n",
    "\n",
    "df = pd.read_csv(url, sep='\\s+', parse_dates=[[0,1,2]])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Year 2061? Do we really have data from this year? Create a function to fix it and apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def change(x:str):\n",
    "    if x.year > 2000:\n",
    "        year = x.year-100\n",
    "    else :\n",
    "        year = x.year\n",
    "    return datetime.date(year, x.month, x.day)\n",
    "\n",
    "df['Yr_Mo_Dy'] = df['Yr_Mo_Dy'].apply(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Set the right dates as the index. Pay attention at the data type, it should be datetime64[ns]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.set_index('Yr_Mo_Dy',inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Compute how many values are missing for each location over the entire record.  \n",
    "#### They should be ignored in all calculations below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RPT'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPT    6\n",
       "VAL    3\n",
       "ROS    2\n",
       "KIL    5\n",
       "SHA    2\n",
       "BIR    0\n",
       "DUB    3\n",
       "CLA    2\n",
       "MUL    3\n",
       "CLO    1\n",
       "BEL    0\n",
       "MAL    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Compute how many non-missing values there are in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPT    6568\n",
       "VAL    6571\n",
       "ROS    6572\n",
       "KIL    6569\n",
       "SHA    6572\n",
       "BIR    6574\n",
       "DUB    6571\n",
       "CLA    6572\n",
       "MUL    6571\n",
       "CLO    6573\n",
       "BEL    6574\n",
       "MAL    6570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] - df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Calculate the mean windspeeds of the windspeeds over all the locations and all the times.\n",
    "#### A single number for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.227982360836938"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. Create a DataFrame called loc_stats and calculate the min, max and mean windspeeds and standard deviations of the windspeeds at each location over all the days \n",
    "\n",
    "#### A different set of numbers for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPT</th>\n",
       "      <th>VAL</th>\n",
       "      <th>ROS</th>\n",
       "      <th>KIL</th>\n",
       "      <th>SHA</th>\n",
       "      <th>BIR</th>\n",
       "      <th>DUB</th>\n",
       "      <th>CLA</th>\n",
       "      <th>MUL</th>\n",
       "      <th>CLO</th>\n",
       "      <th>BEL</th>\n",
       "      <th>MAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6568.000000</td>\n",
       "      <td>6571.000000</td>\n",
       "      <td>6572.000000</td>\n",
       "      <td>6569.000000</td>\n",
       "      <td>6572.000000</td>\n",
       "      <td>6574.000000</td>\n",
       "      <td>6571.000000</td>\n",
       "      <td>6572.000000</td>\n",
       "      <td>6571.000000</td>\n",
       "      <td>6573.000000</td>\n",
       "      <td>6574.000000</td>\n",
       "      <td>6570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.362987</td>\n",
       "      <td>10.644314</td>\n",
       "      <td>11.660526</td>\n",
       "      <td>6.306468</td>\n",
       "      <td>10.455834</td>\n",
       "      <td>7.092254</td>\n",
       "      <td>9.797343</td>\n",
       "      <td>8.495053</td>\n",
       "      <td>8.493590</td>\n",
       "      <td>8.707332</td>\n",
       "      <td>13.121007</td>\n",
       "      <td>15.599079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.618413</td>\n",
       "      <td>5.267356</td>\n",
       "      <td>5.008450</td>\n",
       "      <td>3.605811</td>\n",
       "      <td>4.936125</td>\n",
       "      <td>3.968683</td>\n",
       "      <td>4.977555</td>\n",
       "      <td>4.499449</td>\n",
       "      <td>4.166872</td>\n",
       "      <td>4.503954</td>\n",
       "      <td>5.835037</td>\n",
       "      <td>6.699794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.120000</td>\n",
       "      <td>6.670000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.090000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>8.710000</td>\n",
       "      <td>10.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.710000</td>\n",
       "      <td>10.170000</td>\n",
       "      <td>10.920000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>9.960000</td>\n",
       "      <td>6.830000</td>\n",
       "      <td>9.210000</td>\n",
       "      <td>8.080000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>8.290000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.920000</td>\n",
       "      <td>14.040000</td>\n",
       "      <td>14.670000</td>\n",
       "      <td>8.420000</td>\n",
       "      <td>13.540000</td>\n",
       "      <td>9.670000</td>\n",
       "      <td>12.960000</td>\n",
       "      <td>11.420000</td>\n",
       "      <td>11.190000</td>\n",
       "      <td>11.630000</td>\n",
       "      <td>16.880000</td>\n",
       "      <td>19.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35.800000</td>\n",
       "      <td>33.370000</td>\n",
       "      <td>33.840000</td>\n",
       "      <td>28.460000</td>\n",
       "      <td>37.540000</td>\n",
       "      <td>26.160000</td>\n",
       "      <td>30.370000</td>\n",
       "      <td>31.080000</td>\n",
       "      <td>25.880000</td>\n",
       "      <td>28.210000</td>\n",
       "      <td>42.380000</td>\n",
       "      <td>42.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RPT          VAL          ROS          KIL          SHA  \\\n",
       "count  6568.000000  6571.000000  6572.000000  6569.000000  6572.000000   \n",
       "mean     12.362987    10.644314    11.660526     6.306468    10.455834   \n",
       "std       5.618413     5.267356     5.008450     3.605811     4.936125   \n",
       "min       0.670000     0.210000     1.500000     0.000000     0.130000   \n",
       "25%       8.120000     6.670000     8.000000     3.580000     6.750000   \n",
       "50%      11.710000    10.170000    10.920000     5.750000     9.960000   \n",
       "75%      15.920000    14.040000    14.670000     8.420000    13.540000   \n",
       "max      35.800000    33.370000    33.840000    28.460000    37.540000   \n",
       "\n",
       "               BIR          DUB          CLA          MUL          CLO  \\\n",
       "count  6574.000000  6571.000000  6572.000000  6571.000000  6573.000000   \n",
       "mean      7.092254     9.797343     8.495053     8.493590     8.707332   \n",
       "std       3.968683     4.977555     4.499449     4.166872     4.503954   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.040000   \n",
       "25%       4.000000     6.000000     5.090000     5.370000     5.330000   \n",
       "50%       6.830000     9.210000     8.080000     8.170000     8.290000   \n",
       "75%       9.670000    12.960000    11.420000    11.190000    11.630000   \n",
       "max      26.160000    30.370000    31.080000    25.880000    28.210000   \n",
       "\n",
       "               BEL          MAL  \n",
       "count  6574.000000  6570.000000  \n",
       "mean     13.121007    15.599079  \n",
       "std       5.835037     6.699794  \n",
       "min       0.130000     0.670000  \n",
       "25%       8.710000    10.710000  \n",
       "50%      12.500000    15.000000  \n",
       "75%      16.880000    19.830000  \n",
       "max      42.380000    42.540000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10. Create a DataFrame called day_stats and calculate the min, max and mean windspeed and standard deviations of the windspeeds across all the locations at each day.\n",
    "\n",
    "#### A different set of numbers for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yr_Mo_Dy\n",
       "1961-01-01    9.29\n",
       "1961-01-02    6.50\n",
       "1961-01-03    6.17\n",
       "1961-01-04    1.79\n",
       "1961-01-05    6.17\n",
       "              ... \n",
       "1978-12-27    8.08\n",
       "1978-12-28    5.00\n",
       "1978-12-29    8.71\n",
       "1978-12-30    9.13\n",
       "1978-12-31    9.59\n",
       "Length: 6574, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11. Find the average windspeed in January for each location.  \n",
    "#### Treat January 1961 and January 1962 both as January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\윤수\\AppData\\Local\\Temp\\ipykernel_30600\\1846091330.py:1: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  df[df.index<pd.to_datetime('1962-01-01')].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RPT    12.299583\n",
       "VAL    10.351796\n",
       "ROS    11.362369\n",
       "KIL     6.958227\n",
       "SHA    10.881763\n",
       "BIR     7.729726\n",
       "DUB     9.733923\n",
       "CLA     8.858788\n",
       "MUL     8.647652\n",
       "CLO     9.835577\n",
       "BEL    13.502795\n",
       "MAL    13.680773\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.index<pd.to_datetime('1962-01-01')].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12. Downsample the record to a yearly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\윤수\\OneDrive\\바탕 화면\\Nyungsu\\코딩\\pandas_exercises\\06_Stats\\Wind_Stats\\Exercises.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/%EC%9C%A4%EC%88%98/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/Nyungsu/%EC%BD%94%EB%94%A9/pandas_exercises/06_Stats/Wind_Stats/Exercises.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mresample(rule\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m3T\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:11414\u001b[0m, in \u001b[0;36mDataFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, loffset, base, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m  11397\u001b[0m \u001b[39m@doc\u001b[39m(NDFrame\u001b[39m.\u001b[39mresample, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_shared_doc_kwargs)\n\u001b[0;32m  11398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresample\u001b[39m(\n\u001b[0;32m  11399\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11412\u001b[0m     group_keys: \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m no_default,\n\u001b[0;32m  11413\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Resampler:\n\u001b[1;32m> 11414\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mresample(\n\u001b[0;32m  11415\u001b[0m         rule\u001b[39m=\u001b[39;49mrule,\n\u001b[0;32m  11416\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m  11417\u001b[0m         closed\u001b[39m=\u001b[39;49mclosed,\n\u001b[0;32m  11418\u001b[0m         label\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m  11419\u001b[0m         convention\u001b[39m=\u001b[39;49mconvention,\n\u001b[0;32m  11420\u001b[0m         kind\u001b[39m=\u001b[39;49mkind,\n\u001b[0;32m  11421\u001b[0m         loffset\u001b[39m=\u001b[39;49mloffset,\n\u001b[0;32m  11422\u001b[0m         base\u001b[39m=\u001b[39;49mbase,\n\u001b[0;32m  11423\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m  11424\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m  11425\u001b[0m         origin\u001b[39m=\u001b[39;49morigin,\n\u001b[0;32m  11426\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m  11427\u001b[0m         group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m  11428\u001b[0m     )\n",
      "File \u001b[1;32mc:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:8863\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, loffset, base, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   8860\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresample\u001b[39;00m \u001b[39mimport\u001b[39;00m get_resampler\n\u001b[0;32m   8862\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8863\u001b[0m \u001b[39mreturn\u001b[39;00m get_resampler(\n\u001b[0;32m   8864\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8865\u001b[0m     freq\u001b[39m=\u001b[39;49mrule,\n\u001b[0;32m   8866\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m   8867\u001b[0m     closed\u001b[39m=\u001b[39;49mclosed,\n\u001b[0;32m   8868\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   8869\u001b[0m     kind\u001b[39m=\u001b[39;49mkind,\n\u001b[0;32m   8870\u001b[0m     loffset\u001b[39m=\u001b[39;49mloffset,\n\u001b[0;32m   8871\u001b[0m     convention\u001b[39m=\u001b[39;49mconvention,\n\u001b[0;32m   8872\u001b[0m     base\u001b[39m=\u001b[39;49mbase,\n\u001b[0;32m   8873\u001b[0m     key\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   8874\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   8875\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n\u001b[0;32m   8876\u001b[0m     offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m   8877\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   8878\u001b[0m )\n",
      "File \u001b[1;32mc:\\anaconda\\lib\\site-packages\\pandas\\core\\resample.py:1518\u001b[0m, in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1514\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m \u001b[39mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m tg \u001b[39m=\u001b[39m TimeGrouper(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 1518\u001b[0m \u001b[39mreturn\u001b[39;00m tg\u001b[39m.\u001b[39;49m_get_resampler(obj, kind\u001b[39m=\u001b[39;49mkind)\n",
      "File \u001b[1;32mc:\\anaconda\\lib\\site-packages\\pandas\\core\\resample.py:1699\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[0;32m   1695\u001b[0m     \u001b[39mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[0;32m   1696\u001b[0m         obj, groupby\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis, group_keys\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroup_keys\n\u001b[0;32m   1697\u001b[0m     )\n\u001b[1;32m-> 1699\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1700\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnly valid with DatetimeIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1701\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1702\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got an instance of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(ax)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1703\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "df.resample(rule='1Y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13. Downsample the record to a monthly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14. Downsample the record to a weekly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15. Calculate the min, max and mean windspeeds and standard deviations of the windspeeds across all locations for each week (assume that the first week starts on January 2 1961) for the first 52 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7288e82646d3164eca24130947288f8779d11454649f2c02a5dfc42af7f324c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
